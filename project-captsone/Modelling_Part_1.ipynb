{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\ali\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle('./X1.pkl')\n",
    "y = pd.read_pickle('./y1.pkl')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    \n",
    "#     print cm\n",
    "#     print cr\n",
    "    print a\n",
    "    return a\n",
    "\n",
    "all_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614793605345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "all_models['lr'] = {'model': lr,\n",
    "                'score': evaluate_model(lr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  36 | elapsed:  9.4min remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  36 | elapsed: 12.0min remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  36 | elapsed: 13.0min remaining:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  36 | elapsed: 13.5min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  36 | elapsed: 13.9min remaining:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed: 14.4min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0}\n",
      "0.644651881971\n",
      "0.643903602959\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "\n",
    "gslr = GridSearchCV(lr,\n",
    "                    params, n_jobs=-1, verbose=30,\n",
    "                    cv=KFold(len(y), n_folds=3, shuffle=True))\n",
    "\n",
    "gslr.fit(X, y)\n",
    "\n",
    "print gslr.best_params_\n",
    "print gslr.best_score_\n",
    "\n",
    "all_models['gslr'] = {'model': gslr.best_estimator_,\n",
    "                             'score': evaluate_model(gslr.best_estimator_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "bagging_params = {'n_estimators': [10, 20],\n",
    "                  'max_samples': [0.7, 1.0],\n",
    "                  'max_features': [0.7, 1.0],\n",
    "                  'bootstrap_features': [True, False]}\n",
    "\n",
    "gsbagginglr = GridSearchCV(BaggingClassifier(gslr.best_estimator_), \n",
    "                           bagging_params, n_jobs=-1, verbose = 50, \n",
    "                           cv=KFold(len(y), n_folds=3, shuffle=True))\n",
    "\n",
    "gsbagginglr.fit(X, y)\n",
    "\n",
    "print gsbagginglr.best_params_\n",
    "print gsbagginglr.best_score_\n",
    "\n",
    "all_models['gsbagginglr'] = {'model': gsbagginglr.best_estimator_,\n",
    "                             'score': evaluate_model(gsbagginglr.best_estimator_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616893342878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier()\n",
    "all_models['et'] = {'model': et,\n",
    "                    'score': evaluate_model(et)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
