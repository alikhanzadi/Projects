{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "## Step 1: Open the `sat_scores.csv` file. Investigate the data, and answer the questions below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What does the data describe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset of SAT scores of US states (year unknown or it could be average over a period). It has a Rate column, Verabal and Math column. Verbal and Math are averages of the state. Rate most likely is participation rate of eligilble studnets in the state in that year (or period).\n",
    "\n",
    "At the very end it has average of all states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Does the data look complete? Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data has no missing values it appears to be complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Create a data dictionary for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Load the data into a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"../assets/sat_scores.csv\") as a:\n",
    "    reader = csv.reader(a)\n",
    "    sat = []\n",
    "    for row in reader:\n",
    "        sat.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['State', 'Rate', 'Verbal', 'Math'],\n",
       " ['CT', '82', '509', '510'],\n",
       " ['NJ', '81', '499', '513'],\n",
       " ['MA', '79', '511', '515'],\n",
       " ['NY', '77', '495', '505'],\n",
       " ['NH', '72', '520', '516'],\n",
       " ['RI', '71', '501', '499'],\n",
       " ['PA', '71', '500', '499'],\n",
       " ['VT', '69', '511', '506'],\n",
       " ['ME', '69', '506', '500'],\n",
       " ['VA', '68', '510', '501'],\n",
       " ['DE', '67', '501', '499'],\n",
       " ['MD', '65', '508', '510'],\n",
       " ['NC', '65', '493', '499'],\n",
       " ['GA', '63', '491', '489'],\n",
       " ['IN', '60', '499', '501'],\n",
       " ['SC', '57', '486', '488'],\n",
       " ['DC', '56', '482', '474'],\n",
       " ['OR', '55', '526', '526'],\n",
       " ['FL', '54', '498', '499'],\n",
       " ['WA', '53', '527', '527'],\n",
       " ['TX', '53', '493', '499'],\n",
       " ['HI', '52', '485', '515'],\n",
       " ['AK', '51', '514', '510'],\n",
       " ['CA', '51', '498', '517'],\n",
       " ['AZ', '34', '523', '525'],\n",
       " ['NV', '33', '509', '515'],\n",
       " ['CO', '31', '539', '542'],\n",
       " ['OH', '26', '534', '439'],\n",
       " ['MT', '23', '539', '539'],\n",
       " ['WV', '18', '527', '512'],\n",
       " ['ID', '17', '543', '542'],\n",
       " ['TN', '13', '562', '553'],\n",
       " ['NM', '13', '551', '542'],\n",
       " ['IL', '12', '576', '589'],\n",
       " ['KY', '12', '550', '550'],\n",
       " ['WY', '11', '547', '545'],\n",
       " ['MI', '11', '561', '572'],\n",
       " ['MN', '9', '580', '589'],\n",
       " ['KS', '9', '577', '580'],\n",
       " ['AL', '9', '559', '554'],\n",
       " ['NE', '8', '562', '568'],\n",
       " ['OK', '8', '567', '561'],\n",
       " ['MO', '8', '577', '577'],\n",
       " ['LA', '7', '564', '562'],\n",
       " ['WI', '6', '584', '596'],\n",
       " ['AR', '6', '562', '550'],\n",
       " ['UT', '5', '575', '570'],\n",
       " ['IA', '5', '593', '603'],\n",
       " ['SD', '4', '577', '582'],\n",
       " ['ND', '4', '592', '599'],\n",
       " ['MS', '4', '566', '551'],\n",
       " ['All', '45', '506', '514']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 6. Extract a list of the labels from the data, and remove them from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CT', 82, 509, 510],\n",
       " ['NJ', 81, 499, 513],\n",
       " ['MA', 79, 511, 515],\n",
       " ['NY', 77, 495, 505],\n",
       " ['NH', 72, 520, 516],\n",
       " ['RI', 71, 501, 499],\n",
       " ['PA', 71, 500, 499],\n",
       " ['VT', 69, 511, 506],\n",
       " ['ME', 69, 506, 500],\n",
       " ['VA', 68, 510, 501],\n",
       " ['DE', 67, 501, 499],\n",
       " ['MD', 65, 508, 510],\n",
       " ['NC', 65, 493, 499],\n",
       " ['GA', 63, 491, 489],\n",
       " ['IN', 60, 499, 501],\n",
       " ['SC', 57, 486, 488],\n",
       " ['DC', 56, 482, 474],\n",
       " ['OR', 55, 526, 526],\n",
       " ['FL', 54, 498, 499],\n",
       " ['WA', 53, 527, 527],\n",
       " ['TX', 53, 493, 499],\n",
       " ['HI', 52, 485, 515],\n",
       " ['AK', 51, 514, 510],\n",
       " ['CA', 51, 498, 517],\n",
       " ['AZ', 34, 523, 525],\n",
       " ['NV', 33, 509, 515],\n",
       " ['CO', 31, 539, 542],\n",
       " ['OH', 26, 534, 439],\n",
       " ['MT', 23, 539, 539],\n",
       " ['WV', 18, 527, 512],\n",
       " ['ID', 17, 543, 542],\n",
       " ['TN', 13, 562, 553],\n",
       " ['NM', 13, 551, 542],\n",
       " ['IL', 12, 576, 589],\n",
       " ['KY', 12, 550, 550],\n",
       " ['WY', 11, 547, 545],\n",
       " ['MI', 11, 561, 572],\n",
       " ['MN', 9, 580, 589],\n",
       " ['KS', 9, 577, 580],\n",
       " ['AL', 9, 559, 554],\n",
       " ['NE', 8, 562, 568],\n",
       " ['OK', 8, 567, 561],\n",
       " ['MO', 8, 577, 577],\n",
       " ['LA', 7, 564, 562],\n",
       " ['WI', 6, 584, 596],\n",
       " ['AR', 6, 562, 550],\n",
       " ['UT', 5, 575, 570],\n",
       " ['IA', 5, 593, 603],\n",
       " ['SD', 4, 577, 582],\n",
       " ['ND', 4, 592, 599]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sat[0]\n",
    "data = sat[1:len(sat)-2]\n",
    "all_line = sat[len(sat)-1]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Create a list of State names extracted from the data. (Hint: use the list of labels to index on the State column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CT',\n",
       " 'NJ',\n",
       " 'MA',\n",
       " 'NY',\n",
       " 'NH',\n",
       " 'RI',\n",
       " 'PA',\n",
       " 'VT',\n",
       " 'ME',\n",
       " 'VA',\n",
       " 'DE',\n",
       " 'MD',\n",
       " 'NC',\n",
       " 'GA',\n",
       " 'IN',\n",
       " 'SC',\n",
       " 'DC',\n",
       " 'OR',\n",
       " 'FL',\n",
       " 'WA',\n",
       " 'TX',\n",
       " 'HI',\n",
       " 'AK',\n",
       " 'CA',\n",
       " 'AZ',\n",
       " 'NV',\n",
       " 'CO',\n",
       " 'OH',\n",
       " 'MT',\n",
       " 'WV',\n",
       " 'ID',\n",
       " 'TN',\n",
       " 'NM',\n",
       " 'IL',\n",
       " 'KY',\n",
       " 'WY',\n",
       " 'MI',\n",
       " 'MN',\n",
       " 'KS',\n",
       " 'AL',\n",
       " 'NE',\n",
       " 'OK',\n",
       " 'MO',\n",
       " 'LA',\n",
       " 'WI',\n",
       " 'AR',\n",
       " 'UT',\n",
       " 'IA',\n",
       " 'SD',\n",
       " 'ND']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = []\n",
    "for row in data:\n",
    "    states.append(row[0])\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Print the types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State <type 'str'>\n",
      "Rate <type 'int'>\n",
      "Verbal <type 'int'>\n",
      "Math <type 'int'>\n"
     ]
    }
   ],
   "source": [
    "#for col in labels:\n",
    "#   for row in data:\n",
    "#       t = type(row)\n",
    "#       print(col, t)\n",
    "#how to check and make sure all items in a column are of the same type\n",
    "for i in range(len(labels)):\n",
    "    print labels[i], type(data[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Do any types need to be reassigned? If so, go ahead and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CT', 82, 509, 510],\n",
       " ['NJ', 81, 499, 513],\n",
       " ['MA', 79, 511, 515],\n",
       " ['NY', 77, 495, 505],\n",
       " ['NH', 72, 520, 516],\n",
       " ['RI', 71, 501, 499],\n",
       " ['PA', 71, 500, 499],\n",
       " ['VT', 69, 511, 506],\n",
       " ['ME', 69, 506, 500],\n",
       " ['VA', 68, 510, 501],\n",
       " ['DE', 67, 501, 499],\n",
       " ['MD', 65, 508, 510],\n",
       " ['NC', 65, 493, 499],\n",
       " ['GA', 63, 491, 489],\n",
       " ['IN', 60, 499, 501],\n",
       " ['SC', 57, 486, 488],\n",
       " ['DC', 56, 482, 474],\n",
       " ['OR', 55, 526, 526],\n",
       " ['FL', 54, 498, 499],\n",
       " ['WA', 53, 527, 527],\n",
       " ['TX', 53, 493, 499],\n",
       " ['HI', 52, 485, 515],\n",
       " ['AK', 51, 514, 510],\n",
       " ['CA', 51, 498, 517],\n",
       " ['AZ', 34, 523, 525],\n",
       " ['NV', 33, 509, 515],\n",
       " ['CO', 31, 539, 542],\n",
       " ['OH', 26, 534, 439],\n",
       " ['MT', 23, 539, 539],\n",
       " ['WV', 18, 527, 512],\n",
       " ['ID', 17, 543, 542],\n",
       " ['TN', 13, 562, 553],\n",
       " ['NM', 13, 551, 542],\n",
       " ['IL', 12, 576, 589],\n",
       " ['KY', 12, 550, 550],\n",
       " ['WY', 11, 547, 545],\n",
       " ['MI', 11, 561, 572],\n",
       " ['MN', 9, 580, 589],\n",
       " ['KS', 9, 577, 580],\n",
       " ['AL', 9, 559, 554],\n",
       " ['NE', 8, 562, 568],\n",
       " ['OK', 8, 567, 561],\n",
       " ['MO', 8, 577, 577],\n",
       " ['LA', 7, 564, 562],\n",
       " ['WI', 6, 584, 596],\n",
       " ['AR', 6, 562, 550],\n",
       " ['UT', 5, 575, 570],\n",
       " ['IA', 5, 593, 603],\n",
       " ['SD', 4, 577, 582],\n",
       " ['ND', 4, 592, 599]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in range(len(data)):\n",
    "    for i in range(1,4):\n",
    "        data[a][i] = int(data[a][i])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "##### 10. Create a dictionary for each column mapping the State to its respective value for that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WA': 527, 'DE': 499, 'DC': 474, 'WI': 596, 'WV': 512, 'HI': 515, 'FL': 499, 'WY': 545, 'NH': 516, 'NJ': 513, 'NM': 542, 'TX': 499, 'LA': 562, 'NC': 499, 'ND': 599, 'NE': 568, 'TN': 553, 'NY': 505, 'PA': 499, 'RI': 499, 'NV': 515, 'VA': 501, 'CO': 542, 'AK': 510, 'AL': 554, 'AR': 550, 'VT': 506, 'IL': 589, 'GA': 489, 'IN': 501, 'IA': 603, 'OK': 561, 'AZ': 525, 'CA': 517, 'ID': 542, 'CT': 510, 'ME': 500, 'MD': 510, 'MA': 515, 'OH': 439, 'UT': 570, 'MO': 577, 'MN': 589, 'MI': 572, 'KS': 580, 'MT': 539, 'SC': 488, 'KY': 550, 'OR': 526, 'SD': 582}\n",
      "{'WA': 53, 'DE': 67, 'DC': 56, 'WI': 6, 'WV': 18, 'HI': 52, 'FL': 54, 'WY': 11, 'NH': 72, 'NJ': 81, 'NM': 13, 'TX': 53, 'LA': 7, 'NC': 65, 'ND': 4, 'NE': 8, 'TN': 13, 'NY': 77, 'PA': 71, 'RI': 71, 'NV': 33, 'VA': 68, 'CO': 31, 'AK': 51, 'AL': 9, 'AR': 6, 'VT': 69, 'IL': 12, 'GA': 63, 'IN': 60, 'IA': 5, 'OK': 8, 'AZ': 34, 'CA': 51, 'ID': 17, 'CT': 82, 'ME': 69, 'MD': 65, 'MA': 79, 'OH': 26, 'UT': 5, 'MO': 8, 'MN': 9, 'MI': 11, 'KS': 9, 'MT': 23, 'SC': 57, 'KY': 12, 'OR': 55, 'SD': 4}\n",
      "{'WA': 527, 'DE': 501, 'DC': 482, 'WI': 584, 'WV': 527, 'HI': 485, 'FL': 498, 'WY': 547, 'NH': 520, 'NJ': 499, 'NM': 551, 'TX': 493, 'LA': 564, 'NC': 493, 'ND': 592, 'NE': 562, 'TN': 562, 'NY': 495, 'PA': 500, 'RI': 501, 'NV': 509, 'VA': 510, 'CO': 539, 'AK': 514, 'AL': 559, 'AR': 562, 'VT': 511, 'IL': 576, 'GA': 491, 'IN': 499, 'IA': 593, 'OK': 567, 'AZ': 523, 'CA': 498, 'ID': 543, 'CT': 509, 'ME': 506, 'MD': 508, 'MA': 511, 'OH': 534, 'UT': 575, 'MO': 577, 'MN': 580, 'MI': 561, 'KS': 577, 'MT': 539, 'SC': 486, 'KY': 550, 'OR': 526, 'SD': 577}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AK': [51, 514, 510],\n",
       " 'AL': [9, 559, 554],\n",
       " 'AR': [6, 562, 550],\n",
       " 'AZ': [34, 523, 525],\n",
       " 'CA': [51, 498, 517],\n",
       " 'CO': [31, 539, 542],\n",
       " 'CT': [82, 509, 510],\n",
       " 'DC': [56, 482, 474],\n",
       " 'DE': [67, 501, 499],\n",
       " 'FL': [54, 498, 499],\n",
       " 'GA': [63, 491, 489],\n",
       " 'HI': [52, 485, 515],\n",
       " 'IA': [5, 593, 603],\n",
       " 'ID': [17, 543, 542],\n",
       " 'IL': [12, 576, 589],\n",
       " 'IN': [60, 499, 501],\n",
       " 'KS': [9, 577, 580],\n",
       " 'KY': [12, 550, 550],\n",
       " 'LA': [7, 564, 562],\n",
       " 'MA': [79, 511, 515],\n",
       " 'MD': [65, 508, 510],\n",
       " 'ME': [69, 506, 500],\n",
       " 'MI': [11, 561, 572],\n",
       " 'MN': [9, 580, 589],\n",
       " 'MO': [8, 577, 577],\n",
       " 'MT': [23, 539, 539],\n",
       " 'NC': [65, 493, 499],\n",
       " 'ND': [4, 592, 599],\n",
       " 'NE': [8, 562, 568],\n",
       " 'NH': [72, 520, 516],\n",
       " 'NJ': [81, 499, 513],\n",
       " 'NM': [13, 551, 542],\n",
       " 'NV': [33, 509, 515],\n",
       " 'NY': [77, 495, 505],\n",
       " 'OH': [26, 534, 439],\n",
       " 'OK': [8, 567, 561],\n",
       " 'OR': [55, 526, 526],\n",
       " 'PA': [71, 500, 499],\n",
       " 'RI': [71, 501, 499],\n",
       " 'SC': [57, 486, 488],\n",
       " 'SD': [4, 577, 582],\n",
       " 'TN': [13, 562, 553],\n",
       " 'TX': [53, 493, 499],\n",
       " 'UT': [5, 575, 570],\n",
       " 'VA': [68, 510, 501],\n",
       " 'VT': [69, 511, 506],\n",
       " 'WA': [53, 527, 527],\n",
       " 'WI': [6, 584, 596],\n",
       " 'WV': [18, 527, 512],\n",
       " 'WY': [11, 547, 545]}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_Rate = {}\n",
    "State_Verbal = {}\n",
    "State_Math = {}\n",
    "for row in data:\n",
    "    State_Rate[row[0]] = row[1]\n",
    "    State_Verbal[row[0]] = row[2]\n",
    "    State_Math[row[0]] = row[3]\n",
    "print State_Math\n",
    "print State_Rate\n",
    "print State_Verbal\n",
    "\n",
    "#or we can look at it this way\n",
    "\n",
    "State_Dict = {}\n",
    "for row in data:\n",
    "    State_Dict [row[0]] = row[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Create a dictionary with the values for each of the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Math': [527,\n",
       "  499,\n",
       "  474,\n",
       "  596,\n",
       "  512,\n",
       "  515,\n",
       "  499,\n",
       "  545,\n",
       "  516,\n",
       "  513,\n",
       "  542,\n",
       "  499,\n",
       "  562,\n",
       "  499,\n",
       "  599,\n",
       "  568,\n",
       "  553,\n",
       "  505,\n",
       "  499,\n",
       "  499,\n",
       "  515,\n",
       "  501,\n",
       "  542,\n",
       "  510,\n",
       "  554,\n",
       "  550,\n",
       "  506,\n",
       "  589,\n",
       "  489,\n",
       "  501,\n",
       "  603,\n",
       "  561,\n",
       "  525,\n",
       "  517,\n",
       "  542,\n",
       "  510,\n",
       "  500,\n",
       "  510,\n",
       "  515,\n",
       "  439,\n",
       "  570,\n",
       "  577,\n",
       "  589,\n",
       "  572,\n",
       "  580,\n",
       "  539,\n",
       "  488,\n",
       "  550,\n",
       "  526,\n",
       "  582],\n",
       " 'Rate': [53,\n",
       "  67,\n",
       "  56,\n",
       "  6,\n",
       "  18,\n",
       "  52,\n",
       "  54,\n",
       "  11,\n",
       "  72,\n",
       "  81,\n",
       "  13,\n",
       "  53,\n",
       "  7,\n",
       "  65,\n",
       "  4,\n",
       "  8,\n",
       "  13,\n",
       "  77,\n",
       "  71,\n",
       "  71,\n",
       "  33,\n",
       "  68,\n",
       "  31,\n",
       "  51,\n",
       "  9,\n",
       "  6,\n",
       "  69,\n",
       "  12,\n",
       "  63,\n",
       "  60,\n",
       "  5,\n",
       "  8,\n",
       "  34,\n",
       "  51,\n",
       "  17,\n",
       "  82,\n",
       "  69,\n",
       "  65,\n",
       "  79,\n",
       "  26,\n",
       "  5,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  23,\n",
       "  57,\n",
       "  12,\n",
       "  55,\n",
       "  4],\n",
       " 'Verbal': [527,\n",
       "  501,\n",
       "  482,\n",
       "  584,\n",
       "  527,\n",
       "  485,\n",
       "  498,\n",
       "  547,\n",
       "  520,\n",
       "  499,\n",
       "  551,\n",
       "  493,\n",
       "  564,\n",
       "  493,\n",
       "  592,\n",
       "  562,\n",
       "  562,\n",
       "  495,\n",
       "  500,\n",
       "  501,\n",
       "  509,\n",
       "  510,\n",
       "  539,\n",
       "  514,\n",
       "  559,\n",
       "  562,\n",
       "  511,\n",
       "  576,\n",
       "  491,\n",
       "  499,\n",
       "  593,\n",
       "  567,\n",
       "  523,\n",
       "  498,\n",
       "  543,\n",
       "  509,\n",
       "  506,\n",
       "  508,\n",
       "  511,\n",
       "  534,\n",
       "  575,\n",
       "  577,\n",
       "  580,\n",
       "  561,\n",
       "  577,\n",
       "  539,\n",
       "  486,\n",
       "  550,\n",
       "  526,\n",
       "  577]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List_of_Dic = [State_Rate, State_Verbal, State_Math]\n",
    "#Attributes = [Rate, Verbal, Math]\n",
    "#i = 0\n",
    "#Master_Dic = {}\n",
    "#Master_Dic = {for i in range(4):\n",
    "#                  Master_Dic[Attributes[i]] = List_of_Dic[i]}\n",
    "#HOW TO CREATE A DIC WITH IN A DIC\n",
    "\n",
    "Score_Dic = {}\n",
    "Score_Dic['Rate']= State_Rate.values()\n",
    "Score_Dic['Verbal']= State_Verbal.values()\n",
    "Score_Dic['Math'] = State_Math.values()\n",
    "Score_Dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Print the min and max of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-73-1e4455c449ad>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-73-1e4455c449ad>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print ('Verbal -', 'Max =', max(State_Verbal.values()), 'Min =', min(State_Verbal.values())\u001b[0m\n\u001b[1;37m                                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print ('Rate - ', 'Max =', max(State_Rate.values()), 'Min =', min(State_Rate.values()))\n",
    "print ('Verbal -', 'Max =', max(State_Verbal.values()), 'Min =', min(State_Verbal.values())\n",
    "print ('Math -', 'Max =', max(State_Math.values()), 'Min =', min(State_Math.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Write a function using only list comprehensions, no loops, to compute Standard Deviation. Print the Standard Deviation of each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'WA': 53, 'DE': 67, 'DC': 56, 'WI': 6, 'WV': 18, 'HI': 52, 'FL': 54, 'WY': 11, 'NH': 72, 'NJ': 81, 'NM': 13, 'TX': 53, 'LA': 7, 'NC': 65, 'ND': 4, 'NE': 8, 'TN': 13, 'NY': 77, 'PA': 71, 'RI': 71, 'NV': 33, 'VA': 68, 'CO': 31, 'AK': 51, 'AL': 9, 'AR': 6, 'VT': 69, 'IL': 12, 'GA': 63, 'IN': 60, 'IA': 5, 'OK': 8, 'AZ': 34, 'CA': 51, 'ID': 17, 'CT': 82, 'ME': 69, 'MD': 65, 'MA': 79, 'OH': 26, 'UT': 5, 'MO': 8, 'MN': 9, 'MI': 11, 'KS': 9, 'MT': 23, 'SC': 57, 'KY': 12, 'OR': 55, 'SD': 4}, {'WA': 527, 'DE': 501, 'DC': 482, 'WI': 584, 'WV': 527, 'HI': 485, 'FL': 498, 'WY': 547, 'NH': 520, 'NJ': 499, 'NM': 551, 'TX': 493, 'LA': 564, 'NC': 493, 'ND': 592, 'NE': 562, 'TN': 562, 'NY': 495, 'PA': 500, 'RI': 501, 'NV': 509, 'VA': 510, 'CO': 539, 'AK': 514, 'AL': 559, 'AR': 562, 'VT': 511, 'IL': 576, 'GA': 491, 'IN': 499, 'IA': 593, 'OK': 567, 'AZ': 523, 'CA': 498, 'ID': 543, 'CT': 509, 'ME': 506, 'MD': 508, 'MA': 511, 'OH': 534, 'UT': 575, 'MO': 577, 'MN': 580, 'MI': 561, 'KS': 577, 'MT': 539, 'SC': 486, 'KY': 550, 'OR': 526, 'SD': 577}, {'WA': 527, 'DE': 499, 'DC': 474, 'WI': 596, 'WV': 512, 'HI': 515, 'FL': 499, 'WY': 545, 'NH': 516, 'NJ': 513, 'NM': 542, 'TX': 499, 'LA': 562, 'NC': 499, 'ND': 599, 'NE': 568, 'TN': 553, 'NY': 505, 'PA': 499, 'RI': 499, 'NV': 515, 'VA': 501, 'CO': 542, 'AK': 510, 'AL': 554, 'AR': 550, 'VT': 506, 'IL': 589, 'GA': 489, 'IN': 501, 'IA': 603, 'OK': 561, 'AZ': 525, 'CA': 517, 'ID': 542, 'CT': 510, 'ME': 500, 'MD': 510, 'MA': 515, 'OH': 439, 'UT': 570, 'MO': 577, 'MN': 589, 'MI': 572, 'KS': 580, 'MT': 539, 'SC': 488, 'KY': 550, 'OR': 526, 'SD': 582}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-2888cd73adb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#stdv = 1/len(dic_column.values())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mstdv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-103-2888cd73adb0>\u001b[0m in \u001b[0;36mstdv\u001b[1;34m(list_dic)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstdv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist_dic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdic_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdic_column\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_dic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msum_dif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdic_column\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdic_column\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_dic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#stdv = 1/len(dic_column.values())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'list'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "columns = [State_Rate, State_Verbal, State_Math]\n",
    "column_names = ['State_Rate', 'State_Verbal', 'State_Math']\n",
    "print columns\n",
    "def stdv (list_dic):\n",
    "    average = [np.mean([dic_column.values()]) for dic_column in list_dic]\n",
    "    #sum_dif = [(cell - average) for cell in dic_column for dic_column in list_dic]\n",
    "    \n",
    "    print average\n",
    "    #stdv = 1/len(dic_column.values())\n",
    "    print average\n",
    "stdv (columns)\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "columns = [State_Rate, State_Verbal, State_Math]\n",
    "column_names = ['State_Rate', 'State_Verbal', 'State_Math']\n",
    "def stdv (list_dic):\n",
    "    averages = [np.mean([dic_column.values()]) for dic_column in list_dic]\n",
    "    sum_dif = [(cell - average) for cell in dic_column.values() for dic_column in list_dic for average in averages]\n",
    "    #stdv = 1/len(dic_column.values())\n",
    "    print sum_dif\n",
    "stdv (columns)   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.144509573760956"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.std(State_Rate.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.659999999999997"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mean = np.mean(State_Rate.values())\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531.86000000000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(State_Verbal.values())\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531.46000000000004"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(State_Math.values())\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 14. Using MatPlotLib and PyPlot, plot the distribution of the Rate using histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Plot the Math distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Plot the Verbal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. What is the typical assumption for data distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. Does that distribution hold true for our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Plot some scatterplots. **BONUS**: Use a PyPlot `figure` to present multiple plots at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20. Are there any interesting relationships to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. Create box plots for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BONUS: Using Tableau, create a heat map for each variable using a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
