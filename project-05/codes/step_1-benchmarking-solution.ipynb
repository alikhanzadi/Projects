{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain\n",
    "\n",
    "Prepared for the Neural Information Processing Symposium 2003 Feature Extraction Workshop\n",
    "\n",
    "http://clopinet.com/isabelle/Projects/NIPS2003\n",
    "\n",
    "### Data \n",
    "\n",
    "MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear.\n",
    "\n",
    "MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. \n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Overall, we are Write a simple problem statement with regard to benchmarking your work only.\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "**TODO:** Write a simple solution statement with regard to benchmarking your work only.\n",
    "\n",
    "### Metric\n",
    "\n",
    "**TODO**: Write a statement about the metric you will be using. This section is global as it will be the metric you will use throughout this project. Provide a brief justification for choosing this metric.\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "**TODO**: Write a statement explaining that this is the process by which you identify a benchmark for your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Implement the following code pipeline using the functions you write in `lib/project_5.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/benchmarking.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib.project_5_solution import load_data_from_database, \\\n",
    "                                   make_data_dict, \\\n",
    "                                   general_model, \\\n",
    "                                   general_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "madelon_df = load_data_from_database(local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_data_dictionary = make_data_dict(madelon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_data_dictionary = general_transformer(StandardScaler(),\n",
    "                                           this_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_data_dictionary = general_model(LogisticRegression(C=1E10),\n",
    "                                     this_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test',\n",
       " 'processes',\n",
       " 'X_train',\n",
       " 'test_score',\n",
       " 'train_score',\n",
       " 'y_train',\n",
       " 'y',\n",
       " 'X',\n",
       " 'y_test']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_data_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " LogisticRegression(C=10000000000.0, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_data_dictionary['processes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785333333333\n",
      "0.518\n"
     ]
    }
   ],
   "source": [
    "print(this_data_dictionary['train_score'])\n",
    "print(this_data_dictionary['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778666666667\n",
      "0.528\n"
     ]
    }
   ],
   "source": [
    "this_data_dictionary = make_data_dict(madelon_df)\n",
    "this_data_dictionary = general_transformer(StandardScaler(),\n",
    "                                           this_data_dictionary)\n",
    "this_data_dictionary = general_model(LogisticRegression(C=1E10),\n",
    "                                     this_data_dictionary)\n",
    "print(this_data_dictionary['train_score'])\n",
    "print(this_data_dictionary['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798666666667\n",
      "0.546\n"
     ]
    }
   ],
   "source": [
    "this_data_dictionary = make_data_dict(madelon_df, random_state=42)\n",
    "this_data_dictionary = general_transformer(StandardScaler(),\n",
    "                                           this_data_dictionary)\n",
    "this_data_dictionary = general_model(LogisticRegression(C=1E10),\n",
    "                                     this_data_dictionary)\n",
    "print(this_data_dictionary['train_score'])\n",
    "print(this_data_dictionary['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
